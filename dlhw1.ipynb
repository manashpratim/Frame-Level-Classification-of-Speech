{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dlhw1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6gXk6Y26skV",
        "colab_type": "text"
      },
      "source": [
        "#**Read Me**\n",
        "\n",
        "**Files:** I have used the **hw1p2_float16** dataset from Fall 2019 as it is smaller in size. The paths for the files needs to be changed.\n",
        "\n",
        "**Dataloader** In the dataloader, I have padded the feature vector and stacked both the features and labels as one large 2D array each in the **init** part. The concatenation of frames is done in the **get item** part. It might take a long time to load the train data into the train loader depending on the system. \n",
        "\n",
        "**Model** I have used k=13 (input_size=1080), batch size 0f 256, initialized the model with xavier initialization, used batch norm after activations and used GeLU as activation function (torch 1.4 required). I have used Adam Optimizer with default learning rate and reduced the learning rate by 0.5 after every 5 epochs and ran it for around 30 epochs (I do not exactly remember how many epochs I ran, 30 is a conservative estimate).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4PCdYTfZrST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1m6oq8DBXEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install torch===1.4.0 torchvision===0.5.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOH0Wcmhe_7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import sys\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils import data\n",
        "from torchvision import transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "cuda\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DDxMNOsHRh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSpwYFC_etF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = np.load('/content/drive/My Drive/train1.npy',allow_pickle=True)\n",
        "train_labels = np.load('/content/drive/My Drive/train_labels.npy',allow_pickle=True)\n",
        "dev = np.load('/content/drive/My Drive/dev1.npy',allow_pickle=True)\n",
        "dev_labels = np.load('/content/drive/My Drive/dev_labels.npy',allow_pickle=True)\n",
        "test =  np.load('/content/drive/My Drive/test1.npy',allow_pickle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q5rBJM2-D69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDataset(data.Dataset):\n",
        "    def __init__(self, X,Y,k):\n",
        "       \n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        self.k = k\n",
        "        self.samples = []\n",
        "        self.labels = []\n",
        "        self.length = []\n",
        "        self._init_dataset()\n",
        "        self.ind = np.arange(self.length[-1])\n",
        "        km = [self.k*(2*i+1) for i in range(len(self.length))]\n",
        "        \n",
        "        b = 0\n",
        "        for i in range(self.length[-1]):\n",
        "            if i == self.length[b]:\n",
        "                b = b+1\n",
        "                self.ind[i] = self.ind[i] + km[b]\n",
        "            else:\n",
        "                self.ind[i] = self.ind[i] + km[b]\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        print(len(self.samples),len(self.labels))\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        X = np.concatenate((self.samples[self.ind[index]-self.k:self.ind[index]+ self.k+1]),axis=0)\n",
        "        labels = self.labels[index]\n",
        "        return torch.from_numpy(X).float(),torch.tensor(labels).long()\n",
        "    \n",
        "    def _init_dataset(self):\n",
        "        s = 0\n",
        "        for i in range(len(self.X)):\n",
        "            p = np.pad(self.X[i], ((self.k, self.k), (0, 0)), 'constant', constant_values=0)\n",
        "            s = s + len(self.X[i])\n",
        "            self.length.append(s)\n",
        "            self.samples = self.samples + list(p)\n",
        "            self.labels = self.labels + list(self.Y[i]) \n",
        "\n",
        "         \n",
        "        return np.array(self.samples), np.array(self.labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uqXbOB0F3J3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestDataset(data.Dataset):\n",
        "    def __init__(self, X,k):\n",
        "       \n",
        "        self.X = X\n",
        "        self.k = k\n",
        "        self.samples = []\n",
        "        self.length = []\n",
        "        self._init_dataset()\n",
        "        self.ind = np.arange(self.length[-1])\n",
        "        km = [self.k*(2*i+1) for i in range(len(self.length))]\n",
        "        \n",
        "        b = 0\n",
        "        for i in range(self.length[-1]):\n",
        "            if i == self.length[b]:\n",
        "                b = b+1\n",
        "                self.ind[i] = self.ind[i] + km[b]\n",
        "            else:\n",
        "                self.ind[i] = self.ind[i] + km[b]\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        print(len(self.samples),self.length[-1])\n",
        "        return self.length[-1]\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        X = np.concatenate((self.samples[self.ind[index]-self.k:self.ind[index]+ self.k+1]),axis=0)\n",
        "        return torch.from_numpy(X).float()\n",
        "    \n",
        "    def _init_dataset(self):\n",
        "        s = 0\n",
        "        for i in range(len(self.X)):\n",
        "            p = np.pad(self.X[i], ((self.k, self.k), (0, 0)), 'constant', constant_values=0)\n",
        "            s = s + len(self.X[i])\n",
        "            self.length.append(s)\n",
        "            self.samples = self.samples + list(p)\n",
        "         \n",
        "        return np.array(self.samples)        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azraNJxHF1Fi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#num_workers = 0 if sys.platform == 'win32' else 2\n",
        "num_workers = 8 if cuda else 0 \n",
        "    \n",
        "# Training\n",
        "train_dataset = MyDataset(train, train_labels,13)\n",
        "\n",
        "train_loader_args = dict(shuffle=True, batch_size=256, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "train_loader = data.DataLoader(train_dataset, **train_loader_args)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KrA5oMUiv7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Validation\n",
        "num_workers = 8 \n",
        "val_dataset = MyDataset(dev, dev_labels,13)\n",
        "val_loader_args = dict(shuffle=False, batch_size=256, num_workers=num_workers, pin_memory=True)\n",
        "val_loader = data.DataLoader(val_dataset, **val_loader_args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5d4y-QpP4DE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing\n",
        "test_dataset = TestDataset(test,13)\n",
        "test_loader_args = dict(shuffle=False, batch_size=1, num_workers=num_workers, pin_memory=True)\n",
        "test_loader = data.DataLoader(test_dataset, **test_loader_args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_KCDxJngZvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_xavier(m):\n",
        "  if type(m) == nn.Linear:\n",
        "    fan_in = m.weight.size()[1]\n",
        "    fan_out = m.weight.size()[0]\n",
        "    std = np.sqrt(1.0/(fan_in + fan_out))\n",
        "    m.weight.data.normal_(0,std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8XMilH2lCcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_hey(m):\n",
        "  if type(m) == nn.Linear:\n",
        "    fan_in = m.weight.size()[1]\n",
        "    fan_out = m.weight.size()[0]\n",
        "    std = np.sqrt(2.0/(fan_in + fan_out))\n",
        "    m.weight.data.normal_(0,std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBwGGZ1rGdjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SIMPLE MODEL DEFINITION\n",
        "class Simple_MLP(nn.Module):\n",
        "    def __init__(self, size_list):\n",
        "        super(Simple_MLP, self).__init__()\n",
        "        layers = []\n",
        "        self.size_list = size_list\n",
        "        for i in range(len(size_list) - 2):\n",
        "            layers.append(nn.Linear(size_list[i],size_list[i+1]))\n",
        "            #layers.append(nn.ReLU())\n",
        "            layers.append(nn.GELU())\n",
        "            layers.append(nn.BatchNorm1d(size_list[i+1]))\n",
        "            #layers.append(nn.Dropout(0.04*i,True))\n",
        "        layers.append(nn.Linear(size_list[-2], size_list[-1]))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58NzYw8PwPCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Simple_MLP([1080, 2048, 2048,  1024, 1024, 1024, 512, 512, 256, 138])\n",
        "model.apply(init_xavier)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "#scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=2, verbose=True)\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "model.to(device)\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0l-C-opGyoS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(model, train_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    total_predictions = 0.0\n",
        "    correct_predictions = 0.0\n",
        "    model.to(device)\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Print Learning Rate\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(train_loader):   \n",
        "        optimizer.zero_grad()   # .backward() accumulates gradients\n",
        "        data = data.to(device)\n",
        "        target = target.to(device) # all data & model on same device\n",
        "\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        \n",
        "        total_predictions += target.size(0)\n",
        "        correct_predictions += (predicted == target).sum().item()\n",
        "        \n",
        "        loss = criterion(outputs, target)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    scheduler.step()\n",
        "    end_time = time.time()\n",
        "    \n",
        "    running_loss /= len(train_loader)\n",
        "    acc = (correct_predictions/total_predictions)*100.0\n",
        "    print('Training Loss: ', running_loss, 'Time: ',end_time - start_time, 's')\n",
        "    print('Training Accuracy: ', acc, '%')\n",
        "    return running_loss,acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTSyBqvElCgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def val_model(model, val_loader, criterion):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        model.to(device)\n",
        "\n",
        "        running_loss = 0.0\n",
        "        total_predictions = 0.0\n",
        "        correct_predictions = 0.0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(val_loader):   \n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            outputs = model(data)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_predictions += target.size(0)\n",
        "            correct_predictions += (predicted == target).sum().item()\n",
        "\n",
        "            loss = criterion(outputs, target).detach()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "\n",
        "        running_loss /= len(val_loader)\n",
        "        acc = (correct_predictions/total_predictions)*100.0\n",
        "        print('Testing Loss: ', running_loss)\n",
        "        print('Testing Accuracy: ', acc, '%')\n",
        "        return running_loss, acc\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPtdXezhQTNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(model, test_loader):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        pred = []\n",
        "\n",
        "        for batch_idx, (data) in enumerate(test_loader):   \n",
        "            data = data.to(device)\n",
        "            outputs = model(data)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            pred.append(predicted.cpu().numpy()[0])\n",
        "\n",
        "        return np.array(pred)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tm_olk-BG6oZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 30\n",
        "Train_acc = []\n",
        "Train_loss = []\n",
        "Val_loss = []\n",
        "Val_acc = []\n",
        "\n",
        "for i in range(n_epochs):\n",
        "    print('Epoch: ',i+1)\n",
        "    print('LR: ', scheduler.get_lr())\n",
        "    train_loss,acc = train_epoch(model, train_loader, criterion, optimizer)\n",
        "    test_loss, test_acc = val_model(model, val_loader, criterion)\n",
        "    Train_loss.append(train_loss)\n",
        "    Train_acc.append(acc)\n",
        "    Val_loss.append(test_loss)\n",
        "    Val_acc.append(test_acc)\n",
        "    print('='*20)\n",
        "    #scheduler.step(test_acc)\n",
        "    torch.save(model.state_dict(), '/content/drive/My Drive/model2.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc-hT8RVT02o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred= test_model(model, test_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MzAX6W1XHtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/mbarman7.csv', 'w') as w:\n",
        "    w.write('id,label\\n')\n",
        "    for i in range(len(pred)):\n",
        "            w.write(str(i)+','+str(pred[i])+'\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdcg3ehg5oud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(Train_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zDH-uzK5xvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title('Val Loss')\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(Val_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VineRmjL51RA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title('Val Accuracy')\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.plot(Val_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}